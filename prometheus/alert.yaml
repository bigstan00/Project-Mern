# groups:
#   - name: backend_alert
#     rules:
#       - alert: HighCPUUsage
#         expr: sum(rate(container_cpu_usage_seconds_total{job="node-exporter"}[5m])) by (instance) > 0.9
#         for: 5m
#         labels:
#           severity: critical
#         annotations:
#           summary: "High CPU Usage detected on instance {{ $labels.instance }}"
#           description: "CPU usage has exceeded 90% for more than 5 minutes."

#       - alert: LowCPUUsage
#         expr: sum(rate(container_cpu_usage_seconds_total{job="app"}[1m])) by (instance) < 0.3
#         for: 2m
#         labels:
#           severity: warning
#         annotations:
#           summary: "Low CPU usage detected"
#           description: "CPU usage is below 30% for more than 2 minutes."

#       - alert: ServiceDown
#         expr: up{job="backend"} == 0
#         for: 30s
#         labels:
#           severity: critical
#         annotations:
#           summary: "Service down!"
#           description: "The service {{ $labels.instance }} is down for more than 30 seconds."

#      - alert: HighRequestLatency
#         expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, instance)) > 0.5
#         for: 5m
#         labels:
#           severity: warning
#         annotations:
#           summary: "High request latency on instance {{ $labels.instance }}"
#           description: "The 95th percentile latency is above 500ms for more than 5 minutes."

        
#       - alert: HighDatabaseErrors
#         expr: increase(db_errors_total[5m]) > 5
#         for: 5m
#         labels:
#           severity: critical
#         annotations:
#           summary: "High number of database errors"
#           description: "More than 5 database errors in the last 5 minutes."

#       - alert: InstanceDown
#         expr: up == 0
#         for: 1m
#         labels: 
#           severity: critical
#         annotations: 
#           summary: "Instance {{ $labels.instance }} is down"
#           description: "Instance {{ $labels.instance }} has been down for more than one minute"




groups:
  - name: backend_alert
    rules:
      - alert: HighCPUUsage
        expr: sum(rate(container_cpu_usage_seconds_total{job="backend"}[2m])) by (instance) > 0.75
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High CPU usage detected on instance {{ $labels.instance }}"
          description: "CPU usage has exceeded 75% for more than 2 minutes."

      - alert: LowCPUUsage
        expr: sum(rate(container_cpu_usage_seconds_total{job="backend"}[1m])) by (instance) < 0.3
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Low CPU usage detected"
          description: "CPU usage is below 30% for more than 2 minutes."

      - alert: ServiceDown
        expr: up{job="backend"} == 0
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "Service down!"
          description: "The service {{ $labels.instance }} is down for more than 30 seconds."

      - alert: HighRequestLatency
        expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, instance)) > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High request latency on instance {{ $labels.instance }}"
          description: "The 95th percentile latency is above 500ms for more than 5 minutes."

      - alert: HighDatabaseErrors
        expr: increase(db_errors_total[5m]) > 5
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High number of database errors"
          description: "More than 5 database errors in the last 5 minutes."

      - alert: InstanceDown
        expr: up == 0
        for: 1m
        labels: 
          severity: critical
        annotations: 
          summary: "Instance {{ $labels.instance }} is down"
          description: "Instance {{ $labels.instance }} has been down for more than one minute."





